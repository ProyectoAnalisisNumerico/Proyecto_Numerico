as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = reorder(predictor, coeficiente), y = coeficiente, fill = coeficiente > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Coeficientes del modelo LASSO",
x = "Variable", y = "Valor del coeficiente") +
theme_bw() +
theme(axis.text.y = element_text(size = 7))
predicciones_train <- predict(modelo, newx = x_train)
training_lasso <- mean((predicciones_train - y_train)^2)
paste("Error (MSE) de entrenamiento:", training_lasso)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_lasso <- mean((predicciones_test - y_test)^2)
paste("Error (MSE) de test:", test_mse_lasso)
MAPE <- function(pred, real) {
mean(abs((real - pred) / real), na.rm = TRUE)
}
MAPE_val <- round(MAPE(predicciones_test, y_test) * 100, 2)
paste("MAPE:", MAPE_val, "%")
# --- ENTRENAMIENTO LASSO CON TRANSFORMACIÓN LOGARÍTMICA ---
# Transformación logarítmica de la variable objetivo
y_train_log <- log1p(y_train)  # log(1 + y)
y_test_log  <- log1p(y_test)
set.seed(123)
cv_lasso_log <- cv.glmnet(
x = x_train,
y = log1p(y_train),   # log(1 + y) para reducir asimetría
alpha = 1,
nfolds = 10
)
# --- PREDICCIÓN SOBRE TEST ---
pred_log <- predict(cv_lasso_log, s = "lambda.min", newx = x_test)
# Revertir la transformación logarítmica
pred <- expm1(pred_log)
# --- CÁLCULO DE MÉTRICAS ---
library(MLmetrics)
mae  <- MAE(y_test, pred)
rmse <- RMSE(y_test, pred)
mape <- MAPE(y_test, pred) * 100   # En porcentaje
cat("Evaluación del modelo LASSO (con log-transformación)\n",
"MAE  :", round(mae, 3), "\n",
"RMSE :", round(rmse, 3), "\n",
"MAPE :", round(mape, 2), "%\n")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(dplyr)
library(stringr)
library(readxl)
datosL <- read_excel("Resultados_de_Análisis_de_Laboratorio_Suelos_en_Colombia_20251027.xlsx")
head(datosL)
# Eliminar las columnas innecesarias dejando aquellas relacionadas con los aspectos fisicos y quimicos
datosL1 <- datosL[, !names(datosL) %in% c(
"Secuencial",
"Fecha de Análisis",
"Departamento",
"Municipio",
"Cultivo",
"Estado",
"Tiempo de establecimiento",
"Fertilizantes aplicados",
"Hierro disponible doble acido",
"Cobre disponible doble acido",
"Manganeso disponible doble acido",
"Zinc disponible doble  acido"
)]
# Verificar que esten las variables que se utilizaran para el modelo Lasso
names(datosL1)
datosL1$Topografia <- as.factor(datosL$Topografia)
datosL1$Drenaje <- as.factor(datosL$Drenaje)
datosL1$Riego <- as.factor(datosL$Riego)
levels(datosL1$Topografia)
levels(datosL1$Drenaje)
levels(datosL1$Riego)
datosL2 <- datosL1
datosL2$Topografia <- recode(datosL2$Topografia,
"Plano" = 5,
"Plano y ondulado" = 4,
"Plano y pendiente" = 4,
"Ligeramente ondulado" = 3,
"Moderadamente ondulado" = 2,
"Ondulado" = 2,
"Ondulado y Pendiente" = 1,
"Pendiente leve" = 1,
"Pendiente moderada" = 1,
"Pendiente" = 1,
"Pendiente fuerte" = 0,
"Fuertemente ondulado" = 0
)
datosL2$Topografia[datosL2$Topografia == "No indica"] <- NA
datosL2$Drenaje <- recode(datosL2$Drenaje,
"Muy mal drenaje" = 0,
"Mal drenaje" = 1,
"Regular drenaje" = 2,
"Buen drenaje" = 3,
"Muy buen drenaje" = 4
)
datosL2$Drenaje[datosL2$Drenaje == "No indica"] <- NA
datosL2$Riego <- recode(datosL2$Riego,
"No Tiene" = 0,
"Gravedad" = 1,
"Por Inundación" = 1,
"Superficial" = 1,
"Superficial - Inundación" = 2,
"Superficial-Aspersión" = 2,
"Superficial - Goteo" = 2,
"Manguera" = 3,
"Cañon" = 3,
"Aspersión" = 4,
"Aspersión - Manguera" = 4,
"Goteo" = 5,
"Aspersión - Goteo" = 5,
"Fertirriego" = 5,
"Goteo - Gravedad" = 5
)
datosL2$Riego[datosL2$Riego %in% c("No indica", "No Indica")] <- NA
datosL2$Topografia <- as.numeric(datosL2$Topografia)
datosL2$Drenaje <- as.numeric(datosL2$Drenaje)
datosL2$Riego <- as.numeric(datosL2$Riego)
limpiar_columna <- function(x) {
x <- as.character(x)
x <- str_trim(x)                # eliminar espacios en blanco
x <- toupper(x)                 # uniformar texto
# Reemplazar ND, NA, vacíos → NA real
x[x %in% c("ND", "NA", "", "N/D", "NULO", "<0.09")] <- NA
# Convertir a numérico de forma segura (sin warnings)
suppressWarnings(as.numeric(x))
}
# Aplicar a las columnas numéricas
cols_numericas <- c(
"pH agua:suelo",
"Materia organica",
"Fósforo Bray II",
"Azufre Fosfato monocalcico",
"Acidez Intercambiable",
"Aluminio intercambiable",
"Calcio intercambiable",
"Magnesio intercambiable",
"Potasio intercambiable",
"Sodio intercambiable",
"capacidad de intercambio cationico",
"Conductividad electrica",
"Hierro disponible olsen",
"Cobre disponible",
"Manganeso disponible Olsen",
"Zinc disponible Olsen",
"Boro disponible"
)
datosL2[cols_numericas] <- lapply(datosL2[cols_numericas], limpiar_columna)
# Separar variable dependiente (Y)
yL <- datosL2$`Materia organica`
# Seleccionar solo las predictoras numéricas (excluyendo Y)
XL <- datosL2 %>%
select(-`Materia organica`) %>%
select(where(is.numeric))
# Escalar (centrar y normalizar)
X_scaledL <- as.data.frame(scale(XL))
# Verificar medias y desviaciones
apply(X_scaledL, 2, mean, na.rm = TRUE)[1:5]   # deberían ser ~0
apply(X_scaledL, 2, sd, na.rm = TRUE)[1:5]     # deberían ser ~1
datos_finalL <- cbind(X_scaledL, Materia_Organica = yL)
datos_finalL <- na.omit(datos_finalL)
head(datos_finalL)
set.seed(1235)
id_train <- sample(1:nrow(datos_finalL), size = 0.7 * nrow(datos_finalL), replace = F)
datos_train <- datos_finalL[id_train, ]
datos_test  <- datos_finalL[-id_train, ]
dim(datos_train); dim(datos_test)
x_train <- model.matrix(Materia_Organica ~ ., data = datos_train)[, -1] # El -1 quita la primera columna (intercepto)
y_pre_train <- datos_train$Materia_Organica
x_test <- model.matrix(Materia_Organica ~ ., data = datos_test)[, -1]
y_pre_test <- datos_test$Materia_Organica
y_train <- log1p(y_pre_train)
y_test <- log1p(y_pre_test)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 1, # Regularización LASSO (L1)
nlambda = 100,
standardize = TRUE
)
# Error medio de validación cruzada
regularizacion <- modelo$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = modelo$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes en función de la regularización (LASSO)",
x = "λ (penalización logarítmica)",
y = "Valor del coeficiente") +
theme_bw() +
theme(legend.position = "none")
set.seed(123)
cv_error <- cv.glmnet(
x = x_train,
y = y_train,
alpha = 1, # 1 = LASSO
nfolds = 10, # Validación cruzada de 10 pliegues
type.measure = "mse"
)
plot(cv_error)
paste("Mejor Lambda encontrado:", cv_error$lambda.min)
paste("Lambda óptimo + 1 desviación estándar:", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 1,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = reorder(predictor, coeficiente), y = coeficiente, fill = coeficiente > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Coeficientes del modelo LASSO",
x = "Variable", y = "Valor del coeficiente") +
theme_bw() +
theme(axis.text.y = element_text(size = 7))
predicciones_train <- predict(modelo, newx = x_train)
training_lasso <- mean((predicciones_train - y_train)^2)
paste("Error (MSE) de entrenamiento:", training_lasso)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_lasso <- mean((predicciones_test - y_test)^2)
paste("Error (MSE) de test:", test_mse_lasso)
MAPE <- function(pred, real) {
mean(abs((real - pred) / real), na.rm = TRUE)
}
MAPE_val <- round(MAPE(predicciones_test, y_test) * 100, 2)
paste("MAPE:", MAPE_val, "%")
# --- ENTRENAMIENTO LASSO CON TRANSFORMACIÓN LOGARÍTMICA ---
# Transformación logarítmica de la variable objetivo
y_train_log <- log1p(y_train)  # log(1 + y)
y_test_log  <- log1p(y_test)
set.seed(123)
cv_lasso_log <- cv.glmnet(
x = x_train,
y = log1p(y_train),   # log(1 + y) para reducir asimetría
alpha = 1,
nfolds = 10
)
# --- PREDICCIÓN SOBRE TEST ---
pred_log <- predict(cv_lasso_log, s = "lambda.min", newx = x_test)
# Revertir la transformación logarítmica
pred <- expm1(pred_log)
# --- CÁLCULO DE MÉTRICAS ---
library(MLmetrics)
mae  <- MAE(y_test, pred)
rmse <- RMSE(y_test, pred)
mape <- MAPE(y_test, pred) * 100   # En porcentaje
cat("Evaluación del modelo LASSO (con log-transformación)\n",
"MAE  :", round(mae, 3), "\n",
"RMSE :", round(rmse, 3), "\n",
"MAPE :", round(mape, 2), "%\n")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(dplyr)
library(stringr)
library(readxl)
datosL <- read_excel("Resultados_de_Análisis_de_Laboratorio_Suelos_en_Colombia_20251027.xlsx")
head(datosL)
# Eliminar las columnas innecesarias dejando aquellas relacionadas con los aspectos fisicos y quimicos
datosL1 <- datosL[, !names(datosL) %in% c(
"Secuencial",
"Fecha de Análisis",
"Departamento",
"Municipio",
"Cultivo",
"Estado",
"Tiempo de establecimiento",
"Fertilizantes aplicados",
"Hierro disponible doble acido",
"Cobre disponible doble acido",
"Manganeso disponible doble acido",
"Zinc disponible doble  acido"
)]
# Verificar que esten las variables que se utilizaran para el modelo Lasso
names(datosL1)
datosL1$Topografia <- as.factor(datosL$Topografia)
datosL1$Drenaje <- as.factor(datosL$Drenaje)
datosL1$Riego <- as.factor(datosL$Riego)
levels(datosL1$Topografia)
levels(datosL1$Drenaje)
levels(datosL1$Riego)
datosL2 <- datosL1
datosL2$Topografia <- recode(datosL2$Topografia,
"Plano" = 5,
"Plano y ondulado" = 4,
"Plano y pendiente" = 4,
"Ligeramente ondulado" = 3,
"Moderadamente ondulado" = 2,
"Ondulado" = 2,
"Ondulado y Pendiente" = 1,
"Pendiente leve" = 1,
"Pendiente moderada" = 1,
"Pendiente" = 1,
"Pendiente fuerte" = 0,
"Fuertemente ondulado" = 0
)
datosL2$Topografia[datosL2$Topografia == "No indica"] <- NA
datosL2$Drenaje <- recode(datosL2$Drenaje,
"Muy mal drenaje" = 0,
"Mal drenaje" = 1,
"Regular drenaje" = 2,
"Buen drenaje" = 3,
"Muy buen drenaje" = 4
)
datosL2$Drenaje[datosL2$Drenaje == "No indica"] <- NA
datosL2$Riego <- recode(datosL2$Riego,
"No Tiene" = 0,
"Gravedad" = 1,
"Por Inundación" = 1,
"Superficial" = 1,
"Superficial - Inundación" = 2,
"Superficial-Aspersión" = 2,
"Superficial - Goteo" = 2,
"Manguera" = 3,
"Cañon" = 3,
"Aspersión" = 4,
"Aspersión - Manguera" = 4,
"Goteo" = 5,
"Aspersión - Goteo" = 5,
"Fertirriego" = 5,
"Goteo - Gravedad" = 5
)
datosL2$Riego[datosL2$Riego %in% c("No indica", "No Indica")] <- NA
datosL2$Topografia <- as.numeric(datosL2$Topografia)
datosL2$Drenaje <- as.numeric(datosL2$Drenaje)
datosL2$Riego <- as.numeric(datosL2$Riego)
limpiar_columna <- function(x) {
x <- as.character(x)
x <- str_trim(x)                # eliminar espacios en blanco
x <- toupper(x)                 # uniformar texto
# Reemplazar ND, NA, vacíos → NA real
x[x %in% c("ND", "NA", "", "N/D", "NULO", "<0.09")] <- NA
# Convertir a numérico de forma segura (sin warnings)
suppressWarnings(as.numeric(x))
}
# Aplicar a las columnas numéricas
cols_numericas <- c(
"pH agua:suelo",
"Materia organica",
"Fósforo Bray II",
"Azufre Fosfato monocalcico",
"Acidez Intercambiable",
"Aluminio intercambiable",
"Calcio intercambiable",
"Magnesio intercambiable",
"Potasio intercambiable",
"Sodio intercambiable",
"capacidad de intercambio cationico",
"Conductividad electrica",
"Hierro disponible olsen",
"Cobre disponible",
"Manganeso disponible Olsen",
"Zinc disponible Olsen",
"Boro disponible"
)
datosL2[cols_numericas] <- lapply(datosL2[cols_numericas], limpiar_columna)
# Separar variable dependiente (Y)
yL <- datosL2$`Materia organica`
# Seleccionar solo las predictoras numéricas (excluyendo Y)
XL <- datosL2 %>%
select(-`Materia organica`) %>%
select(where(is.numeric))
# Escalar (centrar y normalizar)
X_scaledL <- as.data.frame(scale(XL))
# Verificar medias y desviaciones
apply(X_scaledL, 2, mean, na.rm = TRUE)[1:5]   # deberían ser ~0
apply(X_scaledL, 2, sd, na.rm = TRUE)[1:5]     # deberían ser ~1
datos_finalL <- cbind(X_scaledL, Materia_Organica = yL)
datos_finalL <- na.omit(datos_finalL)
head(datos_finalL)
set.seed(1235)
id_train <- sample(1:nrow(datos_finalL), size = 0.7 * nrow(datos_finalL), replace = F)
datos_train <- datos_finalL[id_train, ]
datos_test  <- datos_finalL[-id_train, ]
dim(datos_train); dim(datos_test)
x_train <- model.matrix(Materia_Organica ~ ., data = datos_train)[, -1] # El -1 quita la primera columna (intercepto)
y_pre_train <- datos_train$Materia_Organica
x_test <- model.matrix(Materia_Organica ~ ., data = datos_test)[, -1]
y_pre_test <- datos_test$Materia_Organica
y_train <- log1p(y_pre_train)
y_test <- log1p(y_pre_test)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 1, # Regularización LASSO (L1)
nlambda = 100,
standardize = TRUE
)
# Error medio de validación cruzada
regularizacion <- modelo$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = modelo$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes en función de la regularización (LASSO)",
x = "λ (penalización logarítmica)",
y = "Valor del coeficiente") +
theme_bw() +
theme(legend.position = "none")
set.seed(123)
cv_error <- cv.glmnet(
x = x_train,
y = y_train,
alpha = 1, # 1 = LASSO
nfolds = 10, # Validación cruzada de 10 pliegues
type.measure = "mse"
)
plot(cv_error)
paste("Mejor Lambda encontrado:", cv_error$lambda.min)
paste("Lambda óptimo + 1 desviación estándar:", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 1,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = reorder(predictor, coeficiente), y = coeficiente, fill = coeficiente > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
labs(title = "Coeficientes del modelo LASSO",
x = "Variable", y = "Valor del coeficiente") +
theme_bw() +
theme(axis.text.y = element_text(size = 7))
predicciones_train <- predict(modelo, newx = x_train)
training_lasso <- mean((predicciones_train - y_train)^2)
paste("Error (MSE) de entrenamiento:", training_lasso)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_lasso <- mean((predicciones_test - y_test)^2)
paste("Error (MSE) de test:", test_mse_lasso)
MAPE <- function(pred, real) {
mean(abs((real - pred) / real), na.rm = TRUE)
}
MAPE_val <- round(MAPE(predicciones_test, y_test) * 100, 2)
paste("MAPE:", MAPE_val, "%")
