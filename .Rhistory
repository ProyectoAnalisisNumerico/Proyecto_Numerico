nfolds = 10,
type.measure = "mse",
standardize = T
)
plot(cv_error)
paste("Mejor Lambda encontrado: ", cv_error$lambda.min)
paste("Mejor Lambda encontrado: ", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 0,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y= coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge TO") +
theme_bw() +
theme(axis.title.x = element_text(size = 6, angle = 45))
# Exportar los coeficientes
library(writexl)
write_xlsx(df_coeficientes, "Coeficientes_ridge_to.xlsx")
predicciones_train <- predict(modelo, newx = x_train)
training_ridge <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento:", training_ridge)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_ridge <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test:", test_mse_ridge)
MAPE = round(MAPE(predicciones_test, y_test)*100, 2)
paste("MAPE:", MAPE, "%")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(readxl)
datos <- read_excel("Base Ridge_Lasso 1.xlsx", sheet = "TD") # Trabajar con una pestaña especifica
datos <- datos[, -1] # Se elimina la primera columna que corresponde a la fecha de los datos
head(datos)
set.seed(1235)
id_train <- sample(1:nrow(datos), size = 0.7*nrow(datos), replace =F)
datos_train <- datos[id_train,]
datos_test <- datos[-id_train,]
dim(datos_train) ; dim(datos_test)
x_train <- model.matrix(expinf12m ~ . , data = datos_train)[,-1] # El -1 quita la primera
y_train <- datos_train$expinf12m
x_test <- model.matrix(expinf12m ~ . , data = datos_test)[,-1] # El -1 quita la primera
y_test <- datos_test$expinf12m
modelo <-glmnet(
x = x_train,
y = y_train,
alpha = 0, # Regularizacion Ridge
nlambda = 100, # Si se desea modificar se debe usar un multiplo de 10
standardize = T # Estandariza las variables
)
regularizacion <- modelo$beta %>%
as.matrix() %>%
t() %>%
as.tibble() %>%
mutate(lambda = modelo$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes en funcion de la regularizacion") +
theme_bw() +
theme(legend.position = "none")
set.seed(123)
cv_error <- cv.glmnet(
x = x_train,
y = y_train,
alpha = 0, # 1 para lasso, 0 para Ridge
nfolds = 10,
type.measure = "mse",
standardize = T
)
plot(cv_error)
paste("Mejor Lambda encontrado: ", cv_error$lambda.min)
paste("Mejor Lambda encontrado: ", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 0,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y= coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge TD") +
theme_bw() +
theme(axis.title.x = element_text(size = 6, angle = 45))
# Exportar los coeficientes
library(writexl)
write_xlsx(df_coeficientes, "Coeficientes_ridge_td.xlsx")
predicciones_train <- predict(modelo, newx = x_train)
training_ridge <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento:", training_ridge)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_ridge <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test:", test_mse_ridge)
MAPE = round(MAPE(predicciones_test, y_test)*100, 2)
paste("MAPE:", MAPE, "%")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(readxl)
datos <- read_excel("Base Ridge_Lasso 1.xlsx", sheet = "Ocupados") # Trabajar con una pestaña especifica
datos <- datos[, -1] # Se elimina la primera columna que corresponde a la fecha de los datos
head(datos)
set.seed(1235)
id_train <- sample(1:nrow(datos), size = 0.7*nrow(datos), replace =F)
datos_train <- datos[id_train,]
datos_test <- datos[-id_train,]
dim(datos_train) ; dim(datos_test)
x_train <- model.matrix(Ocupados ~ . , data = datos_train)[,-1] # El -1 quita la primera
y_train <- datos_train$Ocupados
x_test <- model.matrix(Ocupados ~ . , data = datos_test)[,-1] # El -1 quita la primera
y_test <- datos_test$Ocupados
modelo <-glmnet(
x = x_train,
y = y_train,
alpha = 1, # Regularizacion lasso
nlambda = 100, # Si se desea modificar se debe usar un multiplo de 10
standardize = T # Estandariza las variables
)
regularizacion <- modelo$beta %>%
as.matrix() %>%
t() %>%
as.tibble() %>%
mutate(lambda = modelo$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes en funcion de la regularizacion") +
theme_bw() +
theme(legend.position = "none")
set.seed(123)
cv_error <- cv.glmnet(
x = x_train,
y = y_train,
alpha = 1, # 1 para lasso, no para rai
nfolds = 10,
type.measure = "mse",
standardize = T
)
plot(cv_error)
paste("Mejor Lambda encontrado: ", cv_error$lambda.min)
paste("Mejor Lambda encontrado: ", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 1,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y= coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Lasso Ocupados") +
theme_bw() +
theme(axis.title.x = element_text(size = 6, angle = 45))
# Exportar los coeficientes
library(writexl)
write_xlsx(df_coeficientes, "Coeficientes_lasso_ocupados.xlsx")
predicciones_train <- predict(modelo, newx = x_train)
training_lasso <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento:", training_lasso)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_lasso <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test:", test_mse_lasso)
MAPE = round(MAPE(predicciones_test, y_test)*100, 2)
paste("MAPE:", MAPE, "%")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(readxl)
datos <- read_excel("Base Ridge_Lasso 1.xlsx", sheet = "Ocupados") # Trabajar con una pestaña especifica
datos <- datos[, -1] # Se elimina la primera columna que corresponde a la fecha de los datos
head(datos)
set.seed(1235)
id_train <- sample(1:nrow(datos), size = 0.7*nrow(datos), replace =F)
datos_train <- datos[id_train,]
datos_test <- datos[-id_train,]
dim(datos_train) ; dim(datos_test)
x_train <- model.matrix(Ocupados ~ . , data = datos_train)[,-1] # El -1 quita la primera
y_train <- datos_train$Ocupados
x_test <- model.matrix(Ocupados ~ . , data = datos_test)[,-1] # El -1 quita la primera
y_test <- datos_test$Ocupados
modelo <-glmnet(
x = x_train,
y = y_train,
alpha = 0, # Regularizacion Ridge
nlambda = 100, # Si se desea modificar se debe usar un multiplo de 10
standardize = T # Estandariza las variables
)
regularizacion <- modelo$beta %>%
as.matrix() %>%
t() %>%
as.tibble() %>%
mutate(lambda = modelo$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes en funcion de la regularizacion") +
theme_bw() +
theme(legend.position = "none")
set.seed(123)
cv_error <- cv.glmnet(
x = x_train,
y = y_train,
alpha = 0, # 1 para lasso, 0 para Ridge
nfolds = 10,
type.measure = "mse",
standardize = T
)
plot(cv_error)
paste("Mejor Lambda encontrado: ", cv_error$lambda.min)
paste("Mejor Lambda encontrado: ", cv_error$lambda.1se)
modelo <- glmnet(
x = x_train,
y = y_train,
alpha = 0,
lambda = cv_error$lambda.1se,
standardize = TRUE
)
df_coeficientes <- coef(modelo) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
df_coeficientes %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y= coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge ocupados") +
theme_bw() +
theme(axis.title.x = element_text(size = 6, angle = 45))
# Exportar los coeficientes
library(writexl)
write_xlsx(df_coeficientes, "Coeficientes_ridge_ocupados.xlsx")
predicciones_train <- predict(modelo, newx = x_train)
training_ridge <- mean((predicciones_train - y_train)^2)
paste("Error (mse) de entrenamiento:", training_ridge)
predicciones_test <- predict(modelo, newx = x_test)
test_mse_ridge <- mean((predicciones_test - y_test)^2)
paste("Error (mse) de test:", test_mse_ridge)
MAPE = round(MAPE(predicciones_test, y_test)*100, 2)
paste("MAPE:", MAPE, "%")
# Preparar datos
X_matrixL <- as.matrix(datos_finalL %>% select(-Materia_Organica))
install.packages("faraway")
install.packages("tidyverse")
install.packages("skimr")
install.packages("DataExplorer")
install.packages("scales")
install.packages("corrr")
###### Para el modelamiento #####
install.packages("glmnet")
install.packages("pls")
install.packages("MLmetrics")
install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(dplyr)
library(stringr)
library(readxl)
datosL <- read_excel("Resultados_de_Análisis_de_Laboratorio_Suelos_en_Colombia_20251027.xlsx")
install.packages("DataExplorer")
#install.packages("faraway")
#install.packages("tidyverse")
#install.packages("skimr")
#install.packages("DataExplorer")
#install.packages("scales")
#install.packages("corrr")
###### Para el modelamiento #####
#install.packages("glmnet")
#install.packages("pls")
#install.packages("MLmetrics")
#install.packages("writexl")
library(faraway)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(scales)
library(corrr)
library(glmnet)
library(pls)
library(MLmetrics)
library(dplyr)
library(stringr)
library(readxl)
datosL <- read_excel("Resultados_de_Análisis_de_Laboratorio_Suelos_en_Colombia_20251027.xlsx")
head(datosL)
# Eliminar las columnas innecesarias dejando aquellas relacionadas con los aspectos fisicos y quimicos
datosL1 <- datosL[, !names(datosL) %in% c(
"Secuencial",
"Fecha de Análisis",
"Departamento",
"Municipio",
"Cultivo",
"Estado",
"Tiempo de establecimiento",
"Fertilizantes aplicados",
"Hierro disponible doble acido",
"Cobre disponible doble acido",
"Manganeso disponible doble acido",
"Zinc disponible doble  acido"
)]
# Verificar que esten las variables que se utilizaran para el modelo Lasso
names(datosL1)
datosL1$Topografia <- as.factor(datosL$Topografia)
datosL1$Drenaje <- as.factor(datosL$Drenaje)
datosL1$Riego <- as.factor(datosL$Riego)
levels(datosL1$Topografia)
levels(datosL1$Drenaje)
levels(datosL1$Riego)
datosL2 <- datosL1
datosL2$Topografia <- recode(datosL2$Topografia,
"Plano" = 5,
"Plano y ondulado" = 4,
"Plano y pendiente" = 4,
"Ligeramente ondulado" = 3,
"Moderadamente ondulado" = 2,
"Ondulado" = 2,
"Ondulado y Pendiente" = 1,
"Pendiente leve" = 1,
"Pendiente moderada" = 1,
"Pendiente" = 1,
"Pendiente fuerte" = 0,
"Fuertemente ondulado" = 0
)
datosL2$Topografia[datosL2$Topografia == "No indica"] <- NA
datosL2$Drenaje <- recode(datosL2$Drenaje,
"Muy mal drenaje" = 0,
"Mal drenaje" = 1,
"Regular drenaje" = 2,
"Buen drenaje" = 3,
"Muy buen drenaje" = 4
)
datosL2$Drenaje[datosL2$Drenaje == "No indica"] <- NA
datosL2$Riego <- recode(datosL2$Riego,
"No Tiene" = 0,
"Gravedad" = 1,
"Por Inundación" = 1,
"Superficial" = 1,
"Superficial - Inundación" = 2,
"Superficial-Aspersión" = 2,
"Superficial - Goteo" = 2,
"Manguera" = 3,
"Cañon" = 3,
"Aspersión" = 4,
"Aspersión - Manguera" = 4,
"Goteo" = 5,
"Aspersión - Goteo" = 5,
"Fertirriego" = 5,
"Goteo - Gravedad" = 5
)
datosL2$Riego[datosL2$Riego %in% c("No indica", "No Indica")] <- NA
datosL2$Topografia <- as.numeric(datosL2$Topografia)
datosL2$Drenaje <- as.numeric(datosL2$Drenaje)
datosL2$Riego <- as.numeric(datosL2$Riego)
limpiar_columna <- function(x) {
x <- as.character(x)
x <- str_trim(x)                # eliminar espacios en blanco
x <- toupper(x)                 # uniformar texto
# Reemplazar ND, NA, vacíos → NA real
x[x %in% c("ND", "NA", "", "N/D", "NULO", "<0.09")] <- NA
# Convertir a numérico de forma segura (sin warnings)
suppressWarnings(as.numeric(x))
}
# Aplicar a las columnas numéricas
cols_numericas <- c(
"pH agua:suelo",
"Materia organica",
"Fósforo Bray II",
"Azufre Fosfato monocalcico",
"Acidez Intercambiable",
"Aluminio intercambiable",
"Calcio intercambiable",
"Magnesio intercambiable",
"Potasio intercambiable",
"Sodio intercambiable",
"capacidad de intercambio cationico",
"Conductividad electrica",
"Hierro disponible olsen",
"Cobre disponible",
"Manganeso disponible Olsen",
"Zinc disponible Olsen",
"Boro disponible"
)
datosL2[cols_numericas] <- lapply(datosL2[cols_numericas], limpiar_columna)
# Separar variable dependiente (Y)
yL <- datosL2$`Materia organica`
# Seleccionar solo las predictoras numéricas (excluyendo Y)
XL <- datosL2 %>%
select(-`Materia organica`) %>%
select(where(is.numeric))
# Escalar (centrar y normalizar)
X_scaledL <- as.data.frame(scale(XL))
# Verificar medias y desviaciones
apply(X_scaledL, 2, mean, na.rm = TRUE)[1:5]   # deberían ser ~0
apply(X_scaledL, 2, sd, na.rm = TRUE)[1:5]     # deberían ser ~1
datos_finalL <- cbind(X_scaledL, Materia_Organica = yL)
datos_finalL <- na.omit(datos_finalL)
head(datos_finalL)
# Preparar datos
X_matrixL <- as.matrix(datos_finalL %>% select(-Materia_Organica))
y_vectorL <- as.numeric(datos_finalL$Materia_Organica)
# Preparar datos
X_matrixL <- as.matrix(datos_finalL %>% select(-Materia_Organica))
y_vectorL <- as.numeric(datos_finalL$Materia_Organica)
